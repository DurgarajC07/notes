# âš¡ HTAP Systems - Real-Time Analytics on Transactional Data

> HTAP (Hybrid Transactional/Analytical Processing) systems unify OLTP and OLAP workloads in a single database, eliminating the need for separate systems and ETL pipelines. Understanding HTAP is crucial for modern architectures requiring real-time analytics.

---

## ğŸ“– 1. Concept Explanation

### What is HTAP?

**HTAP (Hybrid Transactional/Analytical Processing):** A database architecture that handles both:

- **OLTP workloads:** Row-based transactional operations (INSERT, UPDATE, DELETE)
- **OLAP workloads:** Column-based analytical queries (aggregations, reports)

...in the **same database, with real-time consistency**.

```
Traditional Architecture (Lambda/Kappa):

OLTP System (MySQL)          ETL Pipeline            OLAP System (Redshift)
â”œâ”€ Row-oriented             â”œâ”€ Batch/Stream         â”œâ”€ Column-oriented
â”œâ”€ Transactions (fast)      â”œâ”€ Lag (minutes-hours)  â”œâ”€ Analytics (complex)
â””â”€ INSERT/UPDATE            â””â”€ Transform data       â””â”€ SELECT with aggregations
                                   â†“
                          âŒ Complexity: Two systems, ETL, data lag

HTAP Architecture (TiDB, CockroachDB, SingleStore):

                    HTAP System
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  OLTP Workloads (Row Store) â”‚
         â”‚  â”œâ”€ Fast transactions       â”‚
         â”‚  â”œâ”€ ACID guarantees         â”‚
         â”‚  â””â”€ Low latency             â”‚
         â”‚                             â”‚
         â”‚  OLAP Workloads (Column Store)â”‚
         â”‚  â”œâ”€ Complex analytics       â”‚
         â”‚  â”œâ”€ Real-time (no ETL lag)  â”‚
         â”‚  â””â”€ Same data, consistent   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
         âœ… Simplicity: One system, no ETL, real-time

```

---

### HTAP vs Traditional Systems

| Aspect                   | Traditional (OLTP + OLAP)   | HTAP                         |
| ------------------------ | --------------------------- | ---------------------------- |
| **Systems**              | Separate (MySQL + Redshift) | Single database              |
| **ETL Required**         | Yes (batch/stream)          | No                           |
| **Data Freshness**       | Lag (minutes to hours)      | Real-time (seconds)          |
| **Complexity**           | High (manage 2 systems)     | Low (single system)          |
| **Consistency**          | Eventual (ETL lag)          | Immediate                    |
| **Operational Overhead** | High (2 databases, ETL)     | Low (1 database)             |
| **Use Case**             | Batch analytics OK          | Real-time analytics required |

---

### How HTAP Works Internally

**Dual Storage Engines:**

```
HTAP Database Architecture:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           SQL Layer (Unified Interface)      â”‚
â”‚  â”œâ”€ Parse SQL                               â”‚
â”‚  â”œâ”€ Optimize (choose row or column store)   â”‚
â”‚  â””â”€ Execute                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“        â†“
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚                 â”‚                 â”‚
     â–¼                 â–¼                 â–¼
Row Store          Column Store    Coordinator
â”œâ”€ B-Tree index    â”œâ”€ Compressed    â”œâ”€ Route queries
â”œâ”€ Row-oriented    â”œâ”€ Column-scan   â”œâ”€ Replicate data
â”œâ”€ OLTP optimized  â”œâ”€ OLAP optimizedâ”œâ”€ Keep in sync
â””â”€ Fast writes     â””â”€ Fast scans    â””â”€ Consistency

Example (TiDB):
â”œâ”€ TiKV: Row store (RocksDB) for OLTP
â”œâ”€ TiFlash: Column store (ClickHouse-like) for OLAP
â””â”€ Raft replication: Keep row/column stores in sync
```

---

## ğŸ§  2. Why It Matters in Real Systems

### Real Success: Booking.com - HTAP for Real-Time Pricing

**Problem:** Separate OLTP (MySQL) and OLAP (Hadoop) systems

**Before (Traditional):**

```
Traditional Architecture:

MySQL (OLTP)                    Hadoop (OLAP)
â”œâ”€ Hotel bookings              â”œâ”€ Price analytics
â”œâ”€ Real-time inventory         â”œâ”€ Demand forecasting
â””â”€ Fast transactions           â””â”€ Batch jobs (4-hour lag)

Problems:
âŒ Pricing decisions based on 4-hour-old data
âŒ Lost revenue (prices not competitive)
âŒ ETL pipeline: Complex, brittle, slow
âŒ Two systems to manage (MySQL + Hadoop)

Example:
- 10 AM: High demand for hotel (detected in real-time)
- 2 PM: Analytics run (4 hours later)
- 2:01 PM: Prices updated (missed peak demand!)
- Revenue lost: Millions/year ğŸ’¥
```

**After (HTAP - TiDB):**

```
HTAP Architecture (TiDB):

        Single TiDB Cluster
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  OLTP: Hotel bookings       â”‚â†â”€ Fast transactions
   â”‚  OLAP: Price analytics      â”‚â†â”€ Real-time analytics
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
   No ETL, No lag, Same data

Benefits:
âœ… Real-time pricing (detect demand instantly)
âœ… Revenue increased 15%
âœ… Simplified architecture (one database)
âœ… No ETL pipeline to maintain

Example:
- 10 AM: High demand detected (real-time query)
- 10:01 AM: Prices adjusted automatically
- Result: Capture peak demand âœ…
```

**Lesson:** HTAP eliminates data lag, enabling real-time business decisions!

---

### Real Disaster: Retail Company - Stale Analytics

**Problem:** Used separate OLTP (PostgreSQL) and OLAP (Redshift) with 6-hour ETL

**What Happened:**

```
Black Friday Sale:

9 AM: Sale starts (huge traffic spike)
â”œâ”€ OLTP (PostgreSQL): Product inventory updated real-time
â””â”€ OLAP (Redshift): Still showing yesterday's data (ETL lag)

10 AM: Analytics dashboard shows:
â”œâ”€ "Plenty of stock available" (6-hour-old data)
â””â”€ Marketing: "Push more ads!" (based on stale data)

Result:
11 AM: Products actually sold out (in real-time)
â”œâ”€ But analytics didn't know (still showing old data)
â”œâ”€ Marketing kept pushing ads (for out-of-stock items)
â””â”€ Angry customers: "Why advertise sold-out products?" ğŸ’¥

Impact:
âŒ Customer complaints: 10,000+
âŒ Wasted ad spend: $500K (ads for unavailable products)
âŒ Lost trust: Customers thought it was false advertising
```

**Solution:** Migrate to HTAP (SingleStore)

```
HTAP System (SingleStore):

9 AM: Sale starts
â”œâ”€ Transactions (OLTP): Inventory updated
â””â”€ Analytics (OLAP): Immediately see updated inventory

10 AM: Analytics dashboard (real-time):
â”œâ”€ "Product X sold out, stop ads"
â”œâ”€ "Product Y low stock, reduce price"
â””â”€ "Product Z high inventory, push more ads"

Result:
âœ… Real-time inventory awareness
âœ… Dynamic ad targeting (no wasted spend)
âœ… Customer satisfaction (accurate availability)

Benefits:
- Revenue increased: 20%
- Ad efficiency: 30% cost reduction
- Customer complaints: Near zero
```

**Lesson:** Stale analytics leads to bad decisions! HTAP provides real-time insights.

---

### Real Success: PingCAP (TiDB) - Gaming Analytics

**Use Case:** Online gaming platform (100M+ users)

**Requirements:**

- Player transactions (purchases, achievements) - OLTP
- Real-time leaderboards, analytics - OLAP
- Sub-second query latency for both

**Architecture:**

```
Traditional Approach (Rejected):
MySQL (OLTP)        â†’  Kafka  â†’   ClickHouse (OLAP)
â”œâ”€ Player data          ETL       â”œâ”€ Leaderboards
â””â”€ Transactions                   â””â”€ Analytics

Problems:
âŒ Leaderboard lag: 5-10 seconds (unacceptable for gaming)
âŒ Complex pipeline (MySQL â†’ Kafka â†’ ClickHouse)
âŒ Data inconsistency (CDC lag)

HTAP Approach (TiDB):
        TiDB Cluster
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ TiKV (Row Store)        â”‚â†â”€ OLTP: Player transactions
   â”‚ TiFlash (Column Store)  â”‚â†â”€ OLAP: Leaderboards, analytics
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      Real-time replication
            â†“
   âœ… Leaderboard updates: <1 second
   âœ… Single database (simple)
   âœ… Strong consistency

Results:
- Leaderboard latency: 500ms (was 10s)
- Player engagement: +25%
- Operational complexity: -60% (one database vs three)
- Cost savings: 40% (no separate OLAP cluster)
```

---

## âš™ï¸ 3. Internal Working

### TiDB Architecture (Row + Column Stores)

```
TiDB HTAP Architecture:

                  TiDB Server (Stateless SQL Layer)
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚  â”œâ”€ SQL parser                       â”‚
             â”‚  â”œâ”€ Query optimizer                  â”‚
             â”‚  â”‚   â”œâ”€ Choose: TiKV or TiFlash?     â”‚
             â”‚  â”‚   â””â”€ Cost-based decision          â”‚
             â”‚  â””â”€ Distributed executor             â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â†“               â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                â”‚    â”‚                â”‚
            â–¼                â–¼    â–¼                â–¼
    TiKV (Row Store)        PD              TiFlash (Column Store)
    â”œâ”€ RocksDB engine   (Coordinator)       â”œâ”€ ClickHouse engine
    â”œâ”€ Raft replication â”œâ”€ Metadata         â”œâ”€ Columnar storage
    â”œâ”€ OLTP optimized   â””â”€ Leader election  â”œâ”€ OLAP optimized
    â””â”€ B-Tree indexes                       â””â”€ Compressed columns

Data Flow:
1. OLTP write â†’ TiKV (row store) â†’ Raft log
2. Raft log â†’ Replicated to TiFlash (column store) asynchronously
3. TiFlash converts rows â†’ columns (background)
4. OLAP query â†’ Optimizer chooses TiFlash (column store)

Example Query:
-- Transactional query (point lookup):
SELECT * FROM users WHERE user_id = 12345;
â””â”€> Routes to TiKV (row store) âœ… Fast!

-- Analytical query (aggregation):
SELECT date, SUM(amount) FROM orders
WHERE date >= '2026-01-01'
GROUP BY date;
â””â”€> Routes to TiFlash (column store) âœ… Fast scan!

Consistency:
â”œâ”€ TiKV (row store): Strong consistency (Raft)
â”œâ”€ TiFlash (column store): Eventually consistent (async replication)
â””â”€ Lag: <1 second (configurable)
```

---

### CockroachDB HTAP (Experimental)

```
CockroachDB Architecture:

           SQL Layer (Unified)
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Vectorized execution    â”‚
       â”‚  â”œâ”€ Columnar in memory   â”‚
       â”‚  â””â”€ Fast aggregations    â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â†“
          Storage Layer
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  RocksDB (Row-oriented)  â”‚
       â”‚  â”œâ”€ MVCC for ACID        â”‚
       â”‚  â””â”€ Raft replication     â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

HTAP Approach:
â”œâ”€ No separate column store (unlike TiDB)
â”œâ”€ Vectorized execution engine (columnar in-memory processing)
â”‚  â””â”€> Scans rows, converts to columnar in memory, processes
â”‚
â””â”€ Benefits:
   âœ… Simpler architecture (no dual storage)
   âŒ OLAP slower than dedicated column store (TiFlash)

Best For:
- Moderate analytics workload
- Strong consistency required everywhere
- Simpler operations (single storage engine)
```

---

### SingleStore (MemSQL) Architecture

```
SingleStore HTAP Architecture:

        Aggregator Nodes (SQL Router)
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚  Query optimization          â”‚
       â”‚  â”œâ”€ Parse SQL                â”‚
       â”‚  â”œâ”€ Distributed planner      â”‚
       â”‚  â””â”€ Result aggregation       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
           Leaf Nodes (Storage)
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Rowstore (OLTP)                  â”‚
    â”‚  â”œâ”€ In-memory skiplist            â”‚
    â”‚  â”œâ”€ ACID transactions             â”‚
    â”‚  â””â”€ Fast point lookups            â”‚
    â”‚                                   â”‚
    â”‚  Columnstore (OLAP)               â”‚
    â”‚  â”œâ”€ Disk-based columnar           â”‚
    â”‚  â”œâ”€ Compressed                    â”‚
    â”‚  â””â”€ Fast scans                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Universal Storage:
â”œâ”€ Tables can be either:
â”‚  â”œâ”€ ROWSTORE (for OLTP workloads)
â”‚  â””â”€ COLUMNSTORE (for OLAP workloads)
â”‚
â”œâ”€ Or HYBRID (both row and column):
â”‚  â””â”€> Rows for recent data (fast writes)
â”‚      Columns for old data (fast analytics)

Example:
CREATE TABLE orders (
    order_id INT PRIMARY KEY,
    user_id INT,
    total DECIMAL(10, 2),
    created_at TIMESTAMP,
    KEY(created_at)
) SHARD KEY (user_id) WITH (
    columnstore = "orders_cs"  -- Hybrid: row + column
);

-- Recent data (last 7 days): Rowstore (fast transactions)
-- Old data (>7 days): Columnstore (fast analytics)
-- Automatic conversion via background process
```

---

## âœ… 4. Best Practices

### 1. Choose HTAP When Real-Time Analytics Required

```python
# âœ… Use HTAP for real-time dashboards

# Traditional (Separate OLTP + OLAP):
# Problem: Dashboard shows stale data (30-minute ETL lag)

class TraditionalDashboard:
    def get_sales_today(self):
        # Query Redshift (OLAP):
        result = redshift.query('''
            SELECT SUM(total) FROM sales
            WHERE date = CURRENT_DATE
        ''')
        # Data is 30 minutes old âŒ
        return result

# âœ… HTAP (Real-Time):
class HTAPDashboard:
    def get_sales_today(self):
        # Query TiDB (HTAP):
        result = tidb.query('''
            SELECT SUM(total) FROM sales
            WHERE date = CURRENT_DATE
        ''')
        # Data is real-time âœ…
        return result

# Use HTAP when:
# âœ… Dashboard refresh: Every minute
# âœ… Decision-making: Requires latest data
# âœ… Use cases: Fraud detection, dynamic pricing, inventory management
```

---

### 2. Design Queries for Column Store Optimization

```sql
-- âœ… HTAP systems optimize columnar queries differently

-- âŒ Bad: SELECT * (row-oriented)
SELECT * FROM orders WHERE date >= '2026-01-01';
-- Fetches all columns (slow in column store)

-- âœ… Good: SELECT specific columns (column-oriented)
SELECT date, SUM(total), COUNT(*) FROM orders
WHERE date >= '2026-01-01'
GROUP BY date;
-- Only reads 'date' and 'total' columns (fast in column store)

-- âŒ Bad: Joins on OLAP queries (slow)
SELECT o.order_id, u.name, p.product_name
FROM orders o
JOIN users u ON o.user_id = u.user_id
JOIN products p ON o.product_id = p.product_id
WHERE o.date >= '2026-01-01';
-- Multiple joins slow in column store

-- âœ… Good: Denormalize for analytics
-- Store user_name, product_name in orders table (for analytics)
SELECT order_id, user_name, product_name, total
FROM orders
WHERE date >= '2026-01-01';
-- No joins, fast column scan âœ…
```

---

### 3. Separate Hot and Cold Data

```python
# âœ… Use HTAP for hot data, archive cold data

class DataLifecycleManagement:
    def __init__(self):
        self.htap_db = TiDBClient()    # HTAP (hot data)
        self.warehouse = S3Client()     # Data lake (cold data)

    def query_recent_orders(self, days=30):
        # Query HTAP database (fast):
        recent_orders = self.htap_db.query('''
            SELECT * FROM orders
            WHERE created_at >= NOW() - INTERVAL ? DAY
        ''', days)
        return recent_orders

    def query_historical_orders(self, start_date, end_date):
        # Query data lake (slower, but cheaper):
        historical_orders = self.warehouse.query(
            bucket='orders-archive',
            prefix=f'year={start_date.year}/month={start_date.month}/'
        )
        return historical_orders

    def archive_old_data(self):
        # Move data older than 90 days to data lake:
        old_orders = self.htap_db.query('''
            SELECT * FROM orders
            WHERE created_at < NOW() - INTERVAL 90 DAY
        ''')

        # Upload to S3:
        self.warehouse.upload(old_orders, bucket='orders-archive')

        # Delete from HTAP database:
        self.htap_db.execute('''
            DELETE FROM orders
            WHERE created_at < NOW() - INTERVAL 90 DAY
        ''')

# Benefits:
# âœ… HTAP database stays small (hot data only)
# âœ… Query performance fast (less data to scan)
# âœ… Cost savings (data lake cheaper than HTAP)
```

---

### 4. Monitor HTAP Workload Balance

```python
# âœ… Track OLTP vs OLAP resource usage

class HTAPMonitoring:
    def monitor_workload(self):
        metrics = {
            'oltp_queries': self.count_oltp_queries(),
            'olap_queries': self.count_olap_queries(),
            'oltp_latency': self.measure_oltp_latency(),
            'olap_latency': self.measure_olap_latency(),
            'cpu_oltp': self.cpu_usage_oltp(),
            'cpu_olap': self.cpu_usage_olap()
        }

        # Alert if OLAP impacting OLTP:
        if metrics['oltp_latency'] > 100:  # >100ms
            alert('OLAP queries impacting OLTP performance!')
            # Solution: Limit OLAP concurrency or add resources

        return metrics

# Best Practices:
# âœ… Separate OLTP and OLAP query traffic (different connection pools)
# âœ… Limit OLAP query concurrency (prevent resource starvation)
# âœ… Schedule heavy analytics during off-peak hours
```

---

## âŒ 5. Common Mistakes

### Mistake 1: Using HTAP as a Replacement for Data Warehouse

```python
# âŒ Bad: Running multi-hour analytics on HTAP database
class BadHTAPUsage:
    def run_massive_report(self):
        # Query scanning entire database (1TB+ data):
        result = tidb.query('''
            SELECT
                user_id,
                COUNT(*) as order_count,
                SUM(total) as revenue,
                AVG(total) as avg_order,
                -- ... 50 more aggregations
            FROM orders
            WHERE created_at >= '2020-01-01'  -- 5 years of data!
            GROUP BY user_id
        ''')
        # Problem: Query runs for 30 minutes, consumes huge resources
        # Impact: OLTP transactions slow down or time out ğŸ’¥

# âœ… Good: Use HTAP for recent data, data warehouse for deep analytics
class GoodHTAPUsage:
    def run_recent_analytics(self):
        # Query HTAP (last 30 days):
        result = tidb.query('''
            SELECT
                date,
                SUM(total) as daily_revenue
            FROM orders
            WHERE created_at >= NOW() - INTERVAL 30 DAY
            GROUP BY date
        ''')
        # Fast query (<1 second) âœ…
        return result

    def run_deep_analytics(self):
        # Query data warehouse (years of data):
        result = snowflake.query('''
            SELECT
                user_id,
                COUNT(*) as lifetime_orders,
                SUM(total) as lifetime_revenue
            FROM orders_archive
            GROUP BY user_id
        ''')
        # Slow query (5 minutes), but doesn't impact OLTP âœ…
        return result

# Lesson: HTAP for real-time + recent data, data warehouse for deep history
```

---

### Mistake 2: Not Understanding Replication Lag

```python
# âŒ Bad: Expecting zero lag between OLTP and OLAP
class BadHTAPAssumption:
    def place_order_and_analyze(self, order_data):
        # 1. Insert order (OLTP â†’ TiKV):
        order_id = tidb.execute('''
            INSERT INTO orders (user_id, total)
            VALUES (?, ?)
            RETURNING order_id
        ''', order_data['user_id'], order_data['total'])

        # 2. Immediately query analytics (OLAP â†’ TiFlash):
        stats = tidb.query('''
            SELECT SUM(total) FROM orders WHERE user_id = ?
        ''', order_data['user_id'])

        # Problem: TiFlash might not have received the row yet!
        # Replication lag: 100ms - 1 second
        # stats might be missing the latest order âŒ

# âœ… Good: Account for replication lag
class GoodHTAPUsage:
    def place_order_and_analyze(self, order_data):
        # 1. Insert order (OLTP):
        order_id = tidb.execute('''
            INSERT INTO orders (user_id, total)
            VALUES (?, ?)
            RETURNING order_id
        ''', order_data['user_id'], order_data['total'])

        # 2. For immediate read, query OLTP store (TiKV):
        stats = tidb.query('''
            SELECT /*+ READ_FROM_STORAGE(TIKV[orders]) */ SUM(total)
            FROM orders WHERE user_id = ?
        ''', order_data['user_id'])
        # Hint forces read from TiKV (row store) âœ…
        # Guaranteed to see latest data

        # OR: Wait for replication (if analytics can tolerate lag):
        time.sleep(0.5)  # Wait 500ms for replication
        stats = tidb.query('SELECT SUM(total) FROM orders WHERE user_id = ?', user_id)
```

---

### Mistake 3: Not Partitioning Large Tables

```sql
-- âŒ Bad: No partitioning (large table scans slow)
CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id INT,
    total DECIMAL(10, 2),
    created_at TIMESTAMP
);

-- Problem: Analytical queries scan entire table (billions of rows)
SELECT date(created_at), SUM(total)
FROM orders
WHERE created_at >= '2026-01-01'
GROUP BY date(created_at);
-- Scans all rows (slow) âŒ

-- âœ… Good: Partition by time (fast time-range queries)
CREATE TABLE orders (
    order_id BIGINT,
    user_id INT,
    total DECIMAL(10, 2),
    created_at TIMESTAMP,
    PRIMARY KEY (order_id, created_at)
) PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION p2026 VALUES LESS THAN (2027)
);

-- Now query only scans relevant partition:
SELECT date(created_at), SUM(total)
FROM orders
WHERE created_at >= '2026-01-01'
GROUP BY date(created_at);
-- Only scans p2026 partition (fast) âœ…
```

---

### Mistake 4: Ignoring OLTP/OLAP Isolation

```python
# âŒ Bad: OLAP queries starving OLTP transactions
class BadResourceManagement:
    def run_analytics(self):
        # Heavy analytical query:
        result = tidb.query('''
            SELECT user_id, COUNT(*) as order_count
            FROM orders
            GROUP BY user_id
        ''')
        # Problem: Query uses 100% CPU for minutes
        # OLTP transactions time out âŒ

# âœ… Good: Isolate OLAP workload
class GoodResourceManagement:
    def __init__(self):
        self.oltp_connection = tidb.connect(
            resource_group='oltp',  # High priority
            max_concurrent_queries=1000
        )

        self.olap_connection = tidb.connect(
            resource_group='olap',  # Low priority
            max_concurrent_queries=10  # Limit concurrency
        )

    def run_transaction(self):
        # OLTP connection (high priority):
        self.oltp_connection.execute('INSERT INTO orders ...')

    def run_analytics(self):
        # OLAP connection (low priority, throttled):
        result = self.olap_connection.query('''
            SELECT user_id, COUNT(*) as order_count
            FROM orders
            GROUP BY user_id
        ''')
        # Limited resources, won't starve OLTP âœ…
```

---

## ğŸ” 6. Security Considerations

### 1. Separate Access Control for OLTP and OLAP

```sql
-- âœ… Different permissions for transactional vs analytical access

-- OLTP role (application users):
CREATE ROLE app_user;
GRANT SELECT, INSERT, UPDATE, DELETE ON orders TO app_user;
-- Can perform transactions âœ…

-- OLAP role (data analysts):
CREATE ROLE analyst;
GRANT SELECT ON orders TO analyst;
-- Read-only access for analytics âœ…
-- Cannot modify data âŒ

-- Data engineer role (can query column store):
CREATE ROLE data_engineer;
GRANT SELECT /*+ READ_FROM_STORAGE(TIFLASH[orders]) */ ON orders TO data_engineer;
-- Can query TiFlash (column store) for analytics
```

---

### 2. Audit OLAP Queries

```python
# âœ… Log all analytical queries (may access sensitive data)

class HTAPAuditLogger:
    def execute_olap_query(self, user, query):
        # Log query before execution:
        audit_log.write({
            'user': user,
            'query_type': 'OLAP',
            'query': query,
            'timestamp': datetime.utcnow(),
            'source_ip': request.remote_addr
        })

        # Execute query:
        result = tidb.query(query)

        # Log result metadata:
        audit_log.write({
            'rows_returned': len(result),
            'execution_time': result.execution_time
        })

        return result
```

---

### 3. Row-Level Security on Analytics

```sql
-- âœ… Enforce RLS (Row-Level Security) on analytical queries

-- Enable RLS:
ALTER TABLE orders ENABLE ROW LEVEL SECURITY;

-- Policy: Analysts can only see their region's data
CREATE POLICY analyst_region_policy ON orders
FOR SELECT
TO analyst
USING (region = current_setting('app.user_region'));

-- Set user context:
SET app.user_region = 'us-west';

-- Query automatically filtered:
SELECT SUM(total) FROM orders;
-- Only returns orders for 'us-west' region âœ…
```

---

## ğŸš€ 7. Performance Optimization Techniques

### 1. Use Hints to Choose Storage Engine

```sql
-- âœ… Force query to use specific storage engine

-- Force TiKV (row store) for OLTP:
SELECT /*+ READ_FROM_STORAGE(TIKV[orders]) */ *
FROM orders
WHERE order_id = 12345;

-- Force TiFlash (column store) for OLAP:
SELECT /*+ READ_FROM_STORAGE(TIFLASH[orders]) */
    date(created_at), SUM(total)
FROM orders
WHERE created_at >= '2026-01-01'
GROUP BY date(created_at);
```

---

### 2. Optimize Column Store Compression

```sql
-- âœ… Choose compression based on data type

-- High cardinality (user_id): LZ4 (fast, moderate compression)
-- Low cardinality (status): Dictionary encoding (high compression)
-- Numeric (total): Delta encoding (high compression)

CREATE TABLE orders (
    order_id BIGINT,
    user_id INT,  -- High cardinality
    status VARCHAR(20),  -- Low cardinality ('pending', 'completed', 'cancelled')
    total DECIMAL(10, 2),  -- Numeric
    created_at TIMESTAMP
) ENGINE = InnoDB
  COMPRESSION = 'lz4';  -- Fast compression

-- TiFlash automatically chooses best compression per column âœ…
```

---

### 3. Pre-Aggregate Common Queries

```sql
-- âœ… Materialized views for frequent analytics

-- Expensive query (runs frequently):
SELECT date(created_at), SUM(total) as daily_revenue
FROM orders
GROUP BY date(created_at);

-- Create materialized view (pre-aggregated):
CREATE MATERIALIZED VIEW daily_revenue_mv AS
SELECT date(created_at) as date, SUM(total) as revenue
FROM orders
GROUP BY date(created_at);

-- Refresh materialized view (every 5 minutes):
REFRESH MATERIALIZED VIEW daily_revenue_mv;

-- Fast query (reads pre-computed data):
SELECT * FROM daily_revenue_mv WHERE date >= '2026-01-01';
-- Instant results âœ…
```

---

## ğŸ§ª 8. Examples

### Example 1: Real-Time E-Commerce Dashboard

```python
class EcommerceDashboard:
    def __init__(self):
        self.tidb = TiDBClient()  # HTAP database

    def get_dashboard_data(self):
        # Real-time metrics (no ETL lag):

        # 1. Today's revenue (OLAP query on column store):
        revenue_today = self.tidb.query('''
            SELECT /*+ READ_FROM_STORAGE(TIFLASH[orders]) */
                SUM(total) as revenue
            FROM orders
            WHERE DATE(created_at) = CURDATE()
        ''').fetchone()['revenue']

        # 2. Hourly sales trend (OLAP):
        hourly_trend = self.tidb.query('''
            SELECT
                HOUR(created_at) as hour,
                COUNT(*) as order_count,
                SUM(total) as revenue
            FROM orders
            WHERE DATE(created_at) = CURDATE()
            GROUP BY HOUR(created_at)
            ORDER BY hour
        ''').fetchall()

        # 3. Top products (OLAP):
        top_products = self.tidb.query('''
            SELECT
                product_id,
                COUNT(*) as sales_count,
                SUM(quantity) as units_sold
            FROM order_items oi
            JOIN orders o ON oi.order_id = o.order_id
            WHERE DATE(o.created_at) = CURDATE()
            GROUP BY product_id
            ORDER BY sales_count DESC
            LIMIT 10
        ''').fetchall()

        # 4. Real-time inventory (OLTP query on row store):
        low_stock_products = self.tidb.query('''
            SELECT /*+ READ_FROM_STORAGE(TIKV[products]) */
                product_id, name, stock_quantity
            FROM products
            WHERE stock_quantity < reorder_threshold
        ''').fetchall()

        return {
            'revenue_today': revenue_today,
            'hourly_trend': hourly_trend,
            'top_products': top_products,
            'low_stock_alert': low_stock_products
        }

# Benefits:
# âœ… Dashboard shows real-time data (no ETL lag)
# âœ… Single query to get all metrics (no joins across databases)
# âœ… OLTP and OLAP in same database (simple architecture)
```

---

### Example 2: Fraud Detection (Real-Time + Historical)

```python
class FraudDetectionSystem:
    def __init__(self):
        self.htap_db = TiDBClient()  # HTAP for real-time + historical

    def check_transaction(self, transaction):
        # Real-time fraud check (combines OLTP + OLAP):

        # 1. Check user's recent transactions (OLTP):
        recent_txns = self.htap_db.query('''
            SELECT /*+ READ_FROM_STORAGE(TIKV[transactions]) */
                COUNT(*) as txn_count,
                SUM(amount) as total_amount
            FROM transactions
            WHERE user_id = ?
              AND created_at >= NOW() - INTERVAL 1 HOUR
        ''', transaction['user_id']).fetchone()

        # 2. Check user's historical patterns (OLAP):
        historical_avg = self.htap_db.query('''
            SELECT /*+ READ_FROM_STORAGE(TIFLASH[transactions]) */
                AVG(amount) as avg_amount,
                MAX(amount) as max_amount
            FROM transactions
            WHERE user_id = ?
              AND created_at >= NOW() - INTERVAL 90 DAY
        ''', transaction['user_id']).fetchone()

        # 3. Fraud detection logic:
        fraud_score = 0

        # High frequency:
        if recent_txns['txn_count'] > 10:
            fraud_score += 30

        # Large amount:
        if transaction['amount'] > historical_avg['max_amount'] * 2:
            fraud_score += 50

        # Unusual pattern:
        if transaction['amount'] > historical_avg['avg_amount'] * 5:
            fraud_score += 20

        # 4. Block if high risk:
        if fraud_score > 70:
            return {'status': 'blocked', 'reason': 'fraud_suspected', 'score': fraud_score}

        # 5. Allow transaction (insert into OLTP):
        self.htap_db.execute('''
            INSERT INTO transactions (user_id, amount, status)
            VALUES (?, ?, 'approved')
        ''', transaction['user_id'], transaction['amount'])

        return {'status': 'approved', 'score': fraud_score}

# Benefits:
# âœ… Real-time fraud detection (immediate decision)
# âœ… Uses historical patterns (OLAP) without ETL lag
# âœ… Single database (simple architecture)
```

---

## ğŸ—ï¸ 9. Real-World Use Cases

### Use Case 1: Booking.com - Dynamic Pricing

**Requirements:**

- Real-time demand monitoring
- Dynamic price adjustments
- Historical pricing analysis

**HTAP Solution (TiDB):**

```
Architecture:
â”œâ”€ OLTP: Hotel bookings (row store - TiKV)
â”œâ”€ OLAP: Demand analytics (column store - TiFlash)
â””â”€ Real-time sync (no ETL)

Workflow:
1. User searches hotel (OLTP query):
   â””â”€> Check availability (TiKV - row store)

2. Simultaneously analyze demand (OLAP query):
   â””â”€> Count searches, bookings in last hour (TiFlash - column store)

3. Dynamic pricing (real-time):
   IF demand_last_hour > historical_avg * 1.5:
       price *= 1.2  # Increase price 20%

4. Update price (OLTP transaction):
   â””â”€> Store new price (TiKV - row store)

Benefits:
âœ… Real-time pricing (no ETL lag)
âœ… Revenue increased 15%
âœ… Simplified architecture (one database)
```

---

### Use Case 2: Ride-Sharing App - Real-Time Driver Analytics

**Requirements:**

- Driver location tracking (OLTP)
- Real-time demand heatmaps (OLAP)
- Surge pricing decisions

**HTAP Solution (SingleStore):**

```
Architecture:
â”œâ”€ Rowstore: Driver locations, trip transactions
â”œâ”€ Columnstore: Demand analytics, heatmaps
â””â”€ Universal storage (hybrid)

Workflow:
1. Driver updates location (OLTP write):
   â””â”€> INSERT INTO driver_locations (driver_id, lat, lon, timestamp)

2. Analyze demand in area (OLAP query):
   â””â”€> SELECT area, COUNT(*) as ride_requests
       FROM ride_requests
       WHERE timestamp >= NOW() - INTERVAL 10 MINUTE
       GROUP BY area

3. Calculate surge pricing (real-time):
   IF ride_requests > drivers_available * 3:
       surge_multiplier = 2.0

4. Update pricing (OLTP):
   â””â”€> UPDATE pricing SET surge = 2.0 WHERE area_id = ?

Benefits:
âœ… Surge pricing updated every minute (was 10 minutes)
âœ… Driver utilization improved 25%
âœ… Customer wait time reduced 30%
```

---

## â“ 10. Frequently Asked Interview Questions

### Q1: What is HTAP and why does it matter?

**Answer:**

**HTAP (Hybrid Transactional/Analytical Processing):** Database that handles both OLTP (transactions) and OLAP (analytics) workloads in a single system with real-time consistency.

**Traditional approach:**

```
OLTP (MySQL)  â†’  ETL Pipeline  â†’  OLAP (Redshift)
â”œâ”€ Fast writes      (hourly/daily)    â”œâ”€ Fast analytics
â””â”€ Transactions                        â””â”€ Stale data (lag)

Problems:
âŒ Data lag (minutes to hours)
âŒ Two systems to manage
âŒ ETL pipeline complexity
âŒ Eventual consistency (ETL lag)
```

**HTAP approach:**

```
HTAP Database (TiDB, SingleStore, CockroachDB)
â”œâ”€ OLTP: Fast transactions (row store)
â”œâ”€ OLAP: Fast analytics (column store)
â””â”€ Real-time sync (no ETL, no lag)

Benefits:
âœ… Real-time analytics (no lag)
âœ… Single system (simpler)
âœ… No ETL pipeline
âœ… Strong consistency
```

**Why it matters:**

1. **Real-time business decisions:**
   - Example: Dynamic pricing based on real-time demand
   - Traditional: Lag = missed opportunities
   - HTAP: Instant insights = better decisions

2. **Simplified architecture:**
   - Traditional: Manage 2 databases + ETL
   - HTAP: Single database

3. **Cost savings:**
   - No separate OLAP cluster
   - No ETL infrastructure

**Real-world example:**

```
E-commerce flash sale:
- 9 AM: Sale starts (huge traffic)
- Traditional: Dashboard shows yesterday's data (useless)
- HTAP: Dashboard shows real-time data (actionable)
  â””â”€> "Product X selling fast â†’ increase ads"
  â””â”€> "Product Y slow â†’ reduce price"
```

---

### Q2: HTAP vs Lambda Architecture - which to choose?

**Answer:**

**Lambda Architecture:**

```
Speed Layer (Real-time)     Batch Layer (Historical)
â”œâ”€ Stream processing        â”œâ”€ Batch processing
â”‚  (Kafka, Flink)          â”‚  (Spark, Hadoop)
â”œâ”€ Recent data (<1 hour)    â”œâ”€ Historical data (years)
â””â”€ Eventual consistency     â””â”€ Strong consistency

Serving Layer:
â””â”€ Merge results from both layers
```

**HTAP:**

```
Single Database (TiDB, SingleStore)
â”œâ”€ Row Store (OLTP)
â”œâ”€ Column Store (OLAP)
â””â”€ Real-time sync
```

**Comparison:**

| Aspect               | Lambda Architecture      | HTAP                     |
| -------------------- | ------------------------ | ------------------------ |
| **Complexity**       | High (3 systems)         | Low (1 system)           |
| **Real-time**        | Yes (speed layer)        | Yes (column store)       |
| **Historical**       | Yes (batch layer)        | Limited (recent data)    |
| **Consistency**      | Eventually consistent    | Strongly consistent      |
| **Operational Cost** | High (manage 3 systems)  | Low (single database)    |
| **Use Case**         | Massive scale (PB+ data) | Moderate scale (TB data) |

**Choose Lambda when:**

- Massive scale (petabytes of data)
- Need both real-time AND deep historical analytics
- Team expertise in distributed systems (Spark, Kafka, Hadoop)
- Example: Netflix, LinkedIn

**Choose HTAP when:**

- Moderate scale (terabytes of data)
- Need real-time analytics on recent data
- Want simplified architecture (single database)
- Example: E-commerce, SaaS platforms

**Hybrid approach:**

```
HTAP (recent data) + Data Lake (historical data)

Architecture:
â”œâ”€ TiDB (HTAP): Last 90 days (real-time analytics)
â”‚  â””â”€> Fast queries, transactional
â”‚
â””â”€ S3 + Redshift: Older data (deep analytics)
   â””â”€> Archive old data monthly

Benefits:
âœ… Real-time analytics on recent data (HTAP)
âœ… Deep historical analysis (data lake)
âœ… Cost-effective (HTAP expensive, data lake cheap)
```

---

### Q3: How do HTAP systems achieve both OLTP and OLAP performance?

**Answer:**

**Dual Storage Architecture:**

```
HTAP Database (e.g., TiDB):

Write Path:
1. Transaction â†’ Row Store (TiKV)
   â””â”€> Optimized for writes (B-Tree index, row-oriented)

2. Raft Log â†’ Replicated
   â””â”€> Durability + consistency

3. Async Replication â†’ Column Store (TiFlash)
   â””â”€> Background process converts rows to columns

Read Path:
â”œâ”€ OLTP Query â†’ Optimizer chooses Row Store
â”‚  â””â”€> Point lookups, range scans (fast)
â”‚
â””â”€ OLAP Query â†’ Optimizer chooses Column Store
   â””â”€> Full scans, aggregations (fast)
```

**Key techniques:**

1. **Separate storage engines:**
   - Row store: Fast writes, point lookups
   - Column store: Fast scans, aggregations

2. **Cost-based optimizer:**

   ```sql
   -- Optimizer chooses storage engine automatically:

   -- OLTP query (row store):
   SELECT * FROM orders WHERE order_id = 12345;
   â””â”€> Optimizer: "Point lookup â†’ Use TiKV (row store)"

   -- OLAP query (column store):
   SELECT date, SUM(total) FROM orders GROUP BY date;
   â””â”€> Optimizer: "Full scan + aggregation â†’ Use TiFlash (column store)"
   ```

3. **Asynchronous replication:**
   - Writes don't wait for column store
   - OLTP performance not impacted
   - OLAP has slight lag (<1 second)

4. **Columnar compression:**
   - Column store compresses data (10x-100x)
   - Smaller data = faster scans

5. **Vectorized execution:**
   - Process multiple rows at once (SIMD)
   - Faster aggregations

**Example performance:**

```
OLTP Queries:
â”œâ”€ Point lookup: 1ms (TiKV row store)
â”œâ”€ Update: 5ms (TiKV row store)
â””â”€> Similar to pure OLTP database (MySQL) âœ…

OLAP Queries:
â”œâ”€ Full table scan + aggregation: 500ms (TiFlash column store)
â”œâ”€ Complex analytics: 2-10 seconds (TiFlash)
â””â”€> 10x-100x faster than row store âœ…
```

---

### Q4: What are the limitations of HTAP systems?

**Answer:**

**Limitations:**

1. **Not for massive historical data (PB+ scale):**
   - HTAP best for recent data (TB scale)
   - Deep historical analytics â†’ Use data warehouse
   - Example: Query 10 years of data â†’ Too slow on HTAP

2. **Replication lag (row â†’ column store):**
   - Typical lag: 100ms - 1 second
   - Not suitable for absolute real-time (e.g., stock trading)
   - Solution: Force read from row store for critical queries

3. **Resource contention:**
   - OLAP queries can starve OLTP transactions
   - Solution: Resource isolation (separate connection pools)

4. **Higher cost than specialized systems:**
   - HTAP more expensive than separate OLTP + data warehouse
   - Trade-off: Simplicity vs cost

5. **Limited ecosystem (vs relational DBs):**
   - Fewer tools, connectors than PostgreSQL/MySQL
   - Smaller community

**When NOT to use HTAP:**

```
âŒ Massive historical analytics (years of data):
   â””â”€> Use: Data warehouse (Redshift, Snowflake) + data lake (S3)

âŒ Absolute zero-lag required:
   â””â”€> Use: Pure OLTP (PostgreSQL) + cache (Redis)

âŒ Simple use cases (no analytics):
   â””â”€> Use: Traditional OLTP database (PostgreSQL, MySQL)

âŒ Budget-constrained:
   â””â”€> Use: PostgreSQL (cheap) + batch ETL to Redshift
```

**Best use case:**

```
âœ… Real-time dashboards (analytics on recent data)
âœ… Dynamic pricing (combine transactions + analytics)
âœ… Fraud detection (real-time + historical patterns)
âœ… Inventory management (transactions + demand forecasting)
```

---

### Q5: How do you migrate from traditional architecture to HTAP?

**Answer:**

**Migration strategy:**

**Phase 1: Assessment (2-4 weeks)**

```
1. Analyze current architecture:
   â”œâ”€ OLTP database: PostgreSQL/MySQL
   â”œâ”€ ETL pipeline: Airflow + Kafka
   â””â”€ OLAP database: Redshift/Snowflake

2. Identify pain points:
   â”œâ”€ ETL lag: How much? (minutes/hours?)
   â”œâ”€ Complexity: How many systems?
   â””â”€ Cost: Current infrastructure cost?

3. Evaluate HTAP fit:
   â”œâ”€ Data volume: <10TB? (HTAP suitable)
   â”œâ”€ Real-time requirement: Yes? (HTAP beneficial)
   â””â”€ Team skills: Can learn new system?
```

**Phase 2: Proof of Concept (4-8 weeks)**

```
1. Set up HTAP database (TiDB/SingleStore):
   â””â”€> Test cluster with sample data

2. Replicate subset of workload:
   â”œâ”€ Migrate 10% of traffic
   â”œâ”€ Test OLTP queries (latency, throughput)
   â””â”€ Test OLAP queries (performance, accuracy)

3. Compare performance:
   â”œâ”€ OLTP latency: HTAP vs current OLTP DB
   â”œâ”€ OLAP latency: HTAP vs current OLAP DB
   â””â”€ ETL lag: Real-time vs current lag

4. Decision:
   â”œâ”€ If HTAP better â†’ Continue migration
   â””â”€ If not â†’ Stick with current architecture
```

**Phase 3: Gradual Migration (3-6 months)**

```
1. Dual-write approach:
   â”œâ”€ Write to both old OLTP and new HTAP
   â”œâ”€ Read from old OLTP initially
   â””â”€> Validate data consistency

2. Switch reads to HTAP:
   â”œâ”€ OLTP reads â†’ HTAP row store
   â”œâ”€ OLAP reads â†’ HTAP column store
   â””â”€> Monitor performance, errors

3. Decommission old systems:
   â”œâ”€ Stop writes to old OLTP
   â”œâ”€ Shut down ETL pipeline
   â””â”€ Decommission OLAP database

4. Optimize HTAP:
   â”œâ”€ Tune queries (use hints)
   â”œâ”€ Partition tables (time-based)
   â””â”€> Monitor resource usage
```

**Example migration (E-commerce):**

```
Before:
â”œâ”€ MySQL (OLTP): Orders, users, products
â”œâ”€ Kafka + Airflow (ETL): 30-minute lag
â””â”€ Redshift (OLAP): Analytics, dashboards

After (HTAP):
â””â”€ TiDB:
   â”œâ”€ TiKV (row store): Orders, users, products (OLTP)
   â””â”€ TiFlash (column store): Analytics, dashboards (OLAP)

Benefits:
âœ… Dashboard lag: 30 minutes â†’ <1 second
âœ… Operational complexity: 3 systems â†’ 1 system
âœ… Cost savings: 40% (no ETL, no separate OLAP cluster)
```

---

## ğŸ§© 11. Design Patterns

### Pattern 1: Hybrid Storage Pattern

**Problem:** Some tables need OLTP, others need OLAP

**Solution:**

```sql
-- Orders: OLTP-heavy (frequent transactions)
CREATE TABLE orders (
    order_id BIGINT PRIMARY KEY,
    user_id INT,
    total DECIMAL(10, 2),
    created_at TIMESTAMP
) ENGINE = InnoDB;  -- Row-oriented storage

-- Order analytics: OLAP-heavy (read-only, aggregations)
CREATE TABLE order_analytics (
    date DATE PRIMARY KEY,
    total_orders INT,
    total_revenue DECIMAL(10, 2),
    avg_order_value DECIMAL(10, 2)
) ENGINE = ColumnStore;  -- Column-oriented storage (SingleStore)

-- Sync via scheduled job:
INSERT INTO order_analytics
SELECT
    DATE(created_at) as date,
    COUNT(*) as total_orders,
    SUM(total) as total_revenue,
    AVG(total) as avg_order_value
FROM orders
WHERE DATE(created_at) = CURDATE()
ON DUPLICATE KEY UPDATE
    total_orders = VALUES(total_orders),
    total_revenue = VALUES(total_revenue),
    avg_order_value = VALUES(avg_order_value);
```

---

### Pattern 2: Time-Partitioned Hot/Cold Data

**Problem:** Recent data needs OLTP+OLAP, old data only OLAP

**Solution:**

```python
class HotColdDataManagement:
    def __init__(self):
        self.htap_db = TiDBClient()  # Hot data (last 90 days)
        self.warehouse = S3Client()   # Cold data (>90 days)

    def query_data(self, start_date, end_date):
        days_old = (datetime.utcnow().date() - end_date).days

        if days_old < 90:
            # Query HTAP (hot data):
            return self.htap_db.query('''
                SELECT * FROM orders
                WHERE created_at BETWEEN ? AND ?
            ''', start_date, end_date)
        else:
            # Query data lake (cold data):
            return self.warehouse.query(
                bucket='orders-archive',
                start_date=start_date,
                end_date=end_date
            )
```

---

## ğŸ“š Summary

**HTAP (Hybrid Transactional/Analytical Processing):**

- âœ… Single database for OLTP + OLAP workloads
- âœ… Real-time analytics (no ETL lag)
- âœ… Dual storage: Row store (OLTP) + Column store (OLAP)
- âœ… Simplified architecture (one database vs multiple)

**HTAP Systems:**

- **TiDB:** Open-source, MySQL-compatible, strong consistency
- **CockroachDB:** PostgreSQL-compatible, global distribution
- **SingleStore:** In-memory, fast analytics, universal storage

**When to use HTAP:**

- Real-time analytics required (dashboards, fraud detection)
- Moderate data scale (<10TB)
- Want simplified architecture (no ETL)

**When NOT to use HTAP:**

- Massive historical data (PB+ scale) â†’ Use data warehouse
- Absolute zero-lag required â†’ Use cache
- Budget-constrained â†’ Use traditional architecture

**Key takeaway:** HTAP eliminates ETL lag and simplifies architecture, ideal for real-time analytics on transactional data!
